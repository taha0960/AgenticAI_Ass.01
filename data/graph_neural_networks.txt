Title: Heterogeneous Graph Attention Networks for Multi-Relational Knowledge Base Completion

Abstract

Graph Neural Networks (GNNs) have demonstrated exceptional capability in learning representations over structured relational data. However, most GNN architectures assume homogeneous graphs where all nodes and edges are of the same type, limiting their applicability to real-world knowledge bases that inherently contain multiple entity and relation types. We propose Heterogeneous Graph Attention Networks (HetGAT), a framework that extends graph attention mechanisms to heterogeneous graphs by introducing type-specific attention functions and relation-aware message passing. HetGAT computes attention coefficients conditioned on both the node features and the relation type connecting neighboring nodes, enabling differential information aggregation across semantic contexts. On the FB15k-237 and WN18RR knowledge base completion benchmarks, HetGAT achieves Mean Reciprocal Rank (MRR) scores of 0.362 and 0.491 respectively, establishing new state-of-the-art results and outperforming previous GNN-based approaches by 4.1% and 3.7% in MRR.

1. Introduction

Graphs provide a natural abstraction for representing relational data, from social networks and molecular structures to knowledge bases and recommendation systems. Graph neural networks learn node representations by iteratively aggregating information from neighboring nodes through message passing. The foundational GNN frameworks, including Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT), apply uniform transformation and aggregation functions to all nodes and edges, implicitly assuming structural and semantic homogeneity.

Knowledge bases such as Freebase and WordNet contain millions of factual triples (head entity, relation, tail entity), where entities span diverse types (persons, locations, concepts) and relations encode varied semantic connections (born_in, part_of, is_a). Knowledge base completion, the task of predicting missing triples, requires models that can reason over this rich heterogeneous structure. Existing approaches either embed entities and relations independently (TransE, RotatE) or apply homogeneous GNNs that ignore type distinctions (R-GCN uses relation-specific weight matrices but lacks attention mechanisms).

2. Methodology

HetGAT introduces three key innovations for heterogeneous graph learning. First, we define type-specific projection matrices that map nodes of different types into a shared representation space while preserving type-specific semantic information. Second, our relation-aware attention mechanism computes attention coefficients using a bilinear function parameterized by the relation type, allowing the model to learn that certain relations require attending to different aspects of neighboring node features. Third, we employ a hierarchical aggregation strategy that first aggregates messages within each relation type and then combines cross-relation aggregations using a second-level attention mechanism, producing final node representations that capture multi-relational context.

The model is trained end-to-end using a contrastive loss function that maximizes the score of true triples relative to corrupted triples generated through negative sampling, with self-adversarial weighting to focus learning on informative negative examples.

3. Results

On FB15k-237, HetGAT achieves an MRR of 0.362 and Hits@10 of 0.541, surpassing CompGCN (MRR=0.348) and RotatE (MRR=0.338). On WN18RR, HetGAT obtains an MRR of 0.491 and Hits@10 of 0.573, outperforming all baselines. Ablation studies confirm that both the relation-aware attention and the hierarchical aggregation contribute significantly, with their removal leading to MRR drops of 2.8% and 1.9% respectively.

4. Conclusion

HetGAT demonstrates that explicitly modeling heterogeneous graph structure through type-aware attention and hierarchical aggregation leads to superior knowledge base completion performance, providing a principled and scalable approach to learning over multi-relational data.
